{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework2-gov-crawler\n",
    "## 卢家希\n",
    "## 学号 15210130070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2015\n",
      "2014\n",
      "2013\n",
      "2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "2010\n",
      "2009\n",
      "2008\n",
      "2007\n",
      "2006\n",
      "2005\n",
      "2004\n",
      "2003\n",
      "2002\n",
      "2001\n",
      "2000\n",
      "1999\n",
      "1998\n",
      "1997\n",
      "1996\n",
      "1995\n",
      "1994\n",
      "1993\n",
      "1992\n",
      "1991\n",
      "1990\n",
      "1989\n",
      "1988\n",
      "1987\n",
      "1986\n",
      "1985\n",
      "1984\n",
      "1983\n",
      "1982\n",
      "1981\n",
      "1980\n",
      "1979\n",
      "1978\n",
      "1975\n",
      "1964\n",
      "1959\n",
      "1960\n",
      "1957\n",
      "1956\n",
      "1955\n",
      "1954\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"http://www.hprc.org.cn/wxzl/wxysl/lczf/\"\n",
    "content = urllib2.urlopen(url).read().decode('gb18030') \n",
    "soup = BeautifulSoup(content, 'html.parser') \n",
    "links=soup.find_all('td',class_='bl')\n",
    "hyperlinks=[]\n",
    "for i in links:\n",
    "    links=i.a['href'].split('./')[1]\n",
    "    hyperlinks.append(url+str(links))\n",
    "\n",
    "def crawler(url_i):\n",
    "    content = urllib2.urlopen(url_i).read().decode('gb18030') \n",
    "    soup = BeautifulSoup(content, 'html.parser') \n",
    "    year = soup.find('span', {'class', 'huang16c'}).text[:4]\n",
    "    year = int(year)\n",
    "    report=soup.find_all('p')\n",
    "    report=''.join([i.text for i in report])\n",
    "    scripts=soup.find_all('script')\n",
    "    countPage =int(''.join(scripts[1]).split('countPage = ')[1].split('//')[0])\n",
    "    if countPage==1:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(1, countPage):\n",
    "            url_child = url_i.split('.html')[0] +'_'+str(i)+'.html'\n",
    "            content = urllib2.urlopen(url_child).read().decode('gb18030') \n",
    "            soup = BeautifulSoup(content)\n",
    "            report_child=soup.find_all('p')\n",
    "            report_child=''.join([i.text for i in report_child])\n",
    "            report=report+report_child\n",
    "    return year,report\n",
    "\n",
    "reports={ }\n",
    "for link in hyperlinks:\n",
    "    year,report=crawler(link)\n",
    "    print year\n",
    "    reports[year] = report\n",
    "\n",
    "with open('C:/Users/lenovo/Desktop/homeworkgov_reports1954-2016.txt', 'wb') as f:\n",
    "    for r in reports:\n",
    "        line = str(r)+'\\t'+reports[r].replace('\\n', '\\t') +'\\n'\n",
    "        f.write(line.encode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
